---
title: "Clasificacion Ordinal ESL Dataset"
author: "joseangeldiazg"
date: "7/2/2018"
output: pdf_document
---

## Clasificación ordinal

Se pide adaptar el proceso de modelos múltiples de clasificación ordinal al conjunto de datos esl con el algoritmo J48 (C4.5). Para ello, se considerará una única partición entrenamiento test aleatoria con 100 ejemplos en el conjunto de test. Este conjunto tiene carácter ordinal y dispone de 9 clases [1, 9]. Una vez generados los modelos desde el conjunto de entrenamiento, habrá que clasificar los 100 ejemplos de test usando la cascada de probabilidades que define el modelo múltiple. 


### Librerias


```{r}
library(RWeka)
```


### Lectura de datos

El primer paso es leer los datos, al ser un fichero **arff** usaremos la funcion read.arff de Rweka. 

```{r}
esl <- read.arff("data/esl.arff")
head(esl)
```

Tras esto construimos los conjuntos de test y training. 

```{r}
set.seed (2)
train=sample(1:nrow(esl), 350)
test=esl[-train ,]
```

### Descomposición del problema

Para poder aplicar los modelos múltiples de clasificación ordinal tendremos que descomponer el problema en el caso de nuestro problema con 9 clases, tendremos que crear 8 dataframes. La idea de no usar el 9º dataset es que al ir calculando las probabilidades en cascada, si llegamos al 8 y no hemos clasificado correctamente implicará que estamos ante un ejemplo de la última por eliminación. 

1- Creamos 8 copias del dataset:

```{r}
data1 <- esl
data2 <- esl
data3 <- esl
data4 <- esl
data5 <- esl
data6 <- esl
data7 <- esl
data8 <- esl
```

2- Utilizamos la función **ifelse** para cambiar las clases de los datasets:

```{r}
data1$out1 <- ifelse(data1$out1>1, 1, 0) 
data2$out1 <- ifelse(data2$out1>2, 1, 0) 
data3$out1 <- ifelse(data3$out1>3, 1, 0) 
data4$out1 <- ifelse(data4$out1>4, 1, 0) 
data5$out1 <- ifelse(data5$out1>5, 1, 0) 
data6$out1 <- ifelse(data6$out1>6, 1, 0) 
data7$out1 <- ifelse(data7$out1>7, 1, 0) 
data8$out1 <- ifelse(data8$out1>8, 1, 0) 
```

3- Pasamos la clase a factor:

```{r}
data1$out1 <- as.factor(data1$out1)
data2$out1 <- as.factor(data2$out1)
data3$out1 <- as.factor(data3$out1)
data4$out1 <- as.factor(data4$out1)
data5$out1 <- as.factor(data5$out1)
data6$out1 <- as.factor(data6$out1)
data7$out1 <- as.factor(data7$out1)
data8$out1 <- as.factor(data8$out1)
```


LLegados a este punto ya tenemos nuestros datasets creados, por lo que podremos aplicar nuestra clasificación:


### Clasificación

Por último creamos un modelo para cada uno de nuestros subproblemas binarios. 

```{r}
m1 <- J48(out1 ~ ., data = data1)
m2 <- J48(out1 ~ ., data = data2)
m3 <- J48(out1 ~ ., data = data3)
m4 <- J48(out1 ~ ., data = data4)
m5 <- J48(out1 ~ ., data = data5)
m6 <- J48(out1 ~ ., data = data6)
m7 <- J48(out1 ~ ., data = data7)
m8 <- J48(out1 ~ ., data = data8)
```


Para indagar en los modelos podemos usar la funcion **evaluate_Weka_classifier**:


```{r}
eval_m1 <- evaluate_Weka_classifier(m1, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m1
```



```{r}
eval_m2 <- evaluate_Weka_classifier(m2, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m2
eval_m3 <- evaluate_Weka_classifier(m3, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m3
eval_m4 <- evaluate_Weka_classifier(m4, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m4
eval_m5 <- evaluate_Weka_classifier(m5, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m5
eval_m6 <- evaluate_Weka_classifier(m6, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m6
eval_m7 <- evaluate_Weka_classifier(m7, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m7
eval_m8 <- evaluate_Weka_classifier(m8, numFolds = 10, complexity = FALSE, class = TRUE)
eval_m8
```

Por último debemos obtener las probabilidades para nuestro conjunto de test de cada uno de los modelos, tras lo cual deberemos obtener la máxima probabilidad para cada clase:


```{r}
pred1<-predict(m1,test[,1:4],type="probability")
pred1
pred2<-predict(m2,test[,1:4],type="probability")
pred2
```

Una vez tengamos este resultado, debemos agregar los resultados para obtener la clasificación de nuestro modelo para el conjunto de test. Esto lo haremos todo en una función que generalice el modelo y realice todo el calculo de manera que nos ofrezca como salida un vector con las clase predicha.  

### Función generalizada:

```{r}
ordinalClassification <- function (df, classcol, testData)
{
  #Obtenemos el número de clase del problema:
  clases<-as.integer(unique(df[,classcol]))
  #Creamos un vector del tamaño de test para contener las probabilidades
  prob<-1:length(testData[,2])
  #Para cada clase menos la última
  for(i in 1:(length(clases)-1))
  {
    #copiamos los datos 
    dataActual <- df
    #creamos el dataset intermedio cambiando las clases en funcion del orden
    dataActual[,classcol] <- ifelse(dataActual[,classcol]>i, 1, 0) 
    dataActual[,classcol] <- as.factor(dataActual[,classcol])
    #Ya tenemos un dataset ahora creamos el modelo y obtenemos la probabilidad para este modelo
    colnames(dataActual)[classcol]<-"class"
    m <- J48(class~ ., data = dataActual)
    pred <- predict(m,testData,type="probability")
    pred <- as.data.frame(pred)
    prob<-cbind(prob,pred$`1`)
  }
  salida<-prob
  #Calculamos las probabilidades ordinales
  for(i in 2:(length(clases)))
  {
    salida[,i]<-prob[,(i-1)]*(1-prob[,i])
    salida[,1]<-(1-prob[,1])
    salida[,length(clases)]<-prob[,(length(clases)-1)]
  }
  
  #Eliminamos el id
  salida<-salida[,-1]
  #Nos quedamos con el indice de la columna que tiene el mayor elemento
  return(apply(salida,1,which.max))
  #return(salida)
}
#salida<-ordinalClassification(esl,5, testData=test)
pred<-ordinalClassification(esl,5, testData=test)
```

Por último obtenemos el accuracy del modelo:

```{r}
accuracy <- sum(pred==test$out1)/length(test$out1)
accuracy
```


Vemos que hemos obtenido casi un 80% de acierto, lo que es un buen resultado y constata la potencia del método a pesar de que la implementación del mismo no es la mejor posible. 